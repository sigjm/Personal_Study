# CS231N - 1장

## 1.컴퓨터 비전의 필요성

`인터넷의 대부분의 데이터는 이미지나 비디오로 이루어져 있다.` 하지만 마치 우주가 우리가 알아낸 물질 4%와 우리가 아직 알아내지 못한 암흑 물질 96%로 이루어진 것처럼, 인터넷에 존재하는 대량의 이미지 데이터도 우리가 이해할 수 있는 부분은 굉장히 적다. 그래서 이런 데이터를 이해하고 활용할 수 있는 능력을 키우는 것은 필수다.

## 2.컴퓨터 비전의 역사

생물은 어느 순간 '눈'이 생겼고 이때부터 비전의 역사가 시작된다. 동물들은 본다는 행위를 통해 사냥하고, 도망치며, 상호작용하는 등의 여러 능동적 행위를 시작했다.

- ##### Hubel & Wiesel, 1959

  고양이에게 여러 종류의 이미지를 보여주고 각 이미지마다 고양이의 어떤 뇌 부위가 반응하는지, 어떻게 반응하는지 등을 연구한 실험이다. 이 실험을 통해 본다는 행위를 할 때 가장 중요한 뇌 부분이 `가장자리(edge)와 관련된 세포들`임을 알 수 있었고, 이를 통해 가장자리를 인식하는 것이 본다는 행위의 첫 시작임을 유추할 수 있는 증거가 되었다.

- ##### Bock world( Larry Roberts 1963 )

  컴퓨터 비전에 대한 첫 논문이라고 볼 수 있다. 도형 이미지를 기하학적 형태로 바꾸고 그것을 재구성하는 것이 목표였다.

- ##### The Summer Vision Project( MIT 1966 )

  MIT의 유명한 프로젝트로 컴퓨터 비전에 대한 체계를 잡으려고 시작한 프로젝트다. 아직도 근본적인 문제들을 연구중이다.

- ##### VISION( David Marr 1970s )

  MIT의 컴퓨터 비전 사이언티스트였던 David Marr가 쓴 책으로 이 책에서 그가 제시한 컴퓨터 비전의 프로세스가 유명하다. 이 방식이 수십년간 컴퓨터 비전에 이상적이 방법으로 생각되고 있고 입문자들도 직관적으로 컴퓨터 비전을 이해할 수 있는 방식이다.

  - ##### Primary sketch : edges, bars, ends, virtual lines, curves, boundaries 등을 찾아야 한다고 설명했다. 이는 아직도 컴퓨터 비전에 영향을 주고 있는 요소들이다.

  - ##### 2 1/2-D sketch : depth, layers, discontinuities를 찾는다.

  - ##### 3-D model representation : 찾아낸 정보들을 종합해 3d 모델링한다

    이후에 사람들은 간단한 도형들을 이해하는 것 이외에 실제 세계를 이해하는 컴퓨터 비전을 추구하기 시작했다. 그래서 사람을 이해하는 모델이 2가지 제시됨.

- ##### Pictorial Structure( Fischler and Elschlager 1973 )

  사람의 주요 부위를 찾고 그 부위들을 잇는다.

- ##### Generalized Cylinder( Brooks & Binford, 1979 )

  사람을 원통 모형들로 파트를 나눈다.

- ##### ( David Lowe, 1980s )

  면도기 이미지를 line이나 edge를 이용해 이해하려 했던 실험

여기까지는 컴퓨터 비전이 단순한 실험에서 그쳤고 실제 생활에 이용할 수 있을 정도로 연구되지는 않았다. 그래서 이후로는 이미지에서 어떤 사물을 인식하는 것이 어렵다면 우선 이미지에서 사물을 뜯어내 보기부터 하자라는 생각이 생겼고, 이렇게 이미지에서 사물을 뜯어내는 것을 `image segmentation`이라고 했다.

- ##### Normalized Cut( Shi & Malik, 1997)

  graph theory 알고리즘을 이용해 image segmentation을 진행한 실험

- ##### Face Detection( Viola & Jones, 2001)

  90년대 00년대에 다양한 머신러닝 모델이 연구되었고, AdaBoost 알고리즘이 실시간 얼굴 인식 문제에 사용되었다. 실제 세계에 사용할 수 있는 기능으로 컴퓨터 비전 분야에서 급격한 변화였다.

- ##### SIFT & Object Recognition( David Lowe, 1999 )

  특정 물체를 인식하는 실험으로 두 이미지에서 특징이 되는 부분을 찾고 이를 매칭한다. 이미지마다 각도나 채도, 명도 등이 달라 이미지가 다르게 보일 수 있지만 물체의 특징 중 일부는 이런 변화에 강인하고 이미지를 대표할 수 있는 특수성이 있다는 것을 발견했고 이를 매칭해 같은 물체를 찾았다.

- ##### Spatial Pyramid Matching

  이런 이미지의 특징을 이용하게 되면서 이미지를 부분적으로 나누고 각 부분에서 뽑아낸 특징들을 특징 디스크립터에 넣고 SVM 알고리즘을 이용해 각 장면이 어떤 장면인지 분류하는 방법

이런 방법은 인간을 인식하는 모델에도 영향을 많이 주게 된다.

- ##### Histogram of gradients( Dalal & Triggs, 2005 )

- ##### Deformable part models( Felzenswalb, McAllester, Ramanan, 2009 )

또한 2000년대 초에 컴퓨터 비전이 해결해야 하는 문제를 하나 정의했는데 그것은 `'객체인식'`이다.

- ##### PASCAL Visual Object Challenge(20 object categories)( 2006-2012 )

  가장 유명한 데이터셋으로 20개의 카테고리를 분류했다. 이를 이용한 객체인식 성능은 계속해서 성장했다.

- ##### IMAGENET

  세상의 모든 객체를 인식할 수 없을까? 과적합을 피할 순 없을까? 라는 두가지 질문을 해결하기 위해 만든 세상에서 가장 큰 데이터셋 프로젝트다. 약 1500만에서 4000만장 정도의 이미지들이 22000 종류로 분류되어있다. 2009년부터는 ImageNet Large-Scale Visual Recognition Challenge를 열어서 더 적합한 이미지 데이터셋을 찾기 위해 노력했다.

## 3.이 강의에서 주목할 주제들

- ##### image classification

  이미지를 보고 분류하는 기술을 의미한다. 음식을 알아보고 칼로리를 알아보기, 예술 작품을 구분하기 등을 예로 들 수 있다. 이렇게 많은 곳에 많은 용도로 쓰일 수 있는 기술이다.

- ##### object detection

  object detection은 image classification과 달리 한 이미지 전체를 하나의 카테고리로 분류하는 것이 아닌 이미지 내에서 여러 카테고리를 찾아내 box를 치는 것이다.

- ##### image captioning

  image captioning은 이미지 내에서 object detection을 하고 이를 이용해 해당 이미지를 설명할 수 있는 자연스러운 문장을 만드는 기술이다.

위에서 설명한 IMAGENET에서는 이미지 분류에 관한 대회를 여는데, 여기서 확연한 성능 향상을 보여준 것이 바로 CNN이다. CNN은 Convolutional Neural Network의 줄임말로 요즘 딥러닝이라는 말이 생기게 한 요소로 볼 수 있다. 이런 CNN을 활용한 여러 모델들이 대회가 열릴 때마다 우승을 했고 각 모델은 점차 깊어지는 추세를 보인다.

CNN은 IMAGENET에서 연 대회를 통해 2012년 즈음에 유명해졌지만, 사실 1998년에 제안된 오래된 아이디어다. 왜 예전에 제안되었음에도 불구하고 CNN이 2012년에서야 유명해졌을까? 이유는 두가지다.

1. ##### 컴퓨팅 파워의 발전

   쉽게 말해 예전에는 컴퓨터가 좋지 않아서 CNN을 실제로 사용할 수 없었다. 컴퓨팅 파워가 발전하면서 연산능력이 향상되어 실제로 해당 이론을 실행할 수 있는 컴퓨팅 환경이 마련된 것이다.

2. ##### 많은 양의 데이터 제공

   PASCAL이나 ImageNet같은 많은 양의 데이터셋을 제공하는 곳이 없었기 때문에 실질적인 학습이 불가했지만 이젠 가능하다.